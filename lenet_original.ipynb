{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:05, 1862255.99it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 2526246.38it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 1754835.19it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 14628635.20it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/ardo/miniconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459064158/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1:\n",
    "'''\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2: LeNet5\n",
    "'''\n",
    "\n",
    "# Modern LeNet uses this layer for C3\n",
    "class C3_layer_full(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer_full, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(6, 16, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer(x)\n",
    "\n",
    "# Original LeNet uses this layer for C3\n",
    "class C3_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3_layer, self).__init__()\n",
    "        self.ch_in_3 = [[0, 1, 2],\n",
    "                        [1, 2, 3],\n",
    "                        [2, 3, 4],\n",
    "                        [3, 4, 5],\n",
    "                        [0, 4, 5],\n",
    "                        [0, 1, 5]] # filter with 3 subset of input channels\n",
    "        self.ch_in_4 = [[0, 1, 2, 3],\n",
    "                        [1, 2, 3, 4],\n",
    "                        [2, 3, 4, 5],\n",
    "                        [0, 3, 4, 5],\n",
    "                        [0, 1, 4, 5],\n",
    "                        [0, 1, 2, 5],\n",
    "                        [0, 1, 3, 4],\n",
    "                        [1, 2, 4, 5],\n",
    "                        [0, 2, 3, 5]] # filter with 4 subset of input channels\n",
    "        # put implementation here\n",
    "        self.conv_layer_ch_in_3 = nn.ModuleList()\n",
    "        for _ in self.ch_in_3:\n",
    "                self.conv_layer_ch_in_3.append(nn.Conv2d(3, 1, kernel_size=5))\n",
    "        self.conv_layer_ch_in_4 = nn.ModuleList()\n",
    "        for _ in self.ch_in_4:\n",
    "                self.conv_layer_ch_in_4.append(nn.Conv2d(4, 1, kernel_size=5))\n",
    "        self.conv_layer_ch_in_6 = nn.Conv2d(6, 1, kernel_size=5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # put implementation here\n",
    "        output = torch.Tensor([]).to(device)\n",
    "        for i, in_channel in enumerate(self.ch_in_3):\n",
    "                output = torch.cat((output, self.conv_layer_ch_in_3[i](x[:, in_channel, :, :])), 1)\n",
    "        for i, in_channel in enumerate(self.ch_in_4):\n",
    "                output = torch.cat((output, self.conv_layer_ch_in_4[i](x[:, in_channel, :, :])), 1)\n",
    "        return torch.cat((output, self.conv_layer_ch_in_6(x)), 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        #padding=2 makes 28x28 image into 32x32\n",
    "        self.C1_layer = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P2_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C3_layer = nn.Sequential(\n",
    "                C3_layer_full(),\n",
    "                #C3_layer(),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.P4_layer = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F6_layer = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        self.F7_layer = nn.Linear(84, 10)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        output = self.C1_layer(x)\n",
    "        output = self.P2_layer(output)\n",
    "        output = self.C3_layer(output)\n",
    "        output = self.P4_layer(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.F6_layer(output)\n",
    "        output = self.F7_layer(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LeNet_Combination(nn.Module) :\n",
    "#     def __init__(self) :\n",
    "#         super(LeNet, self).__init__()\n",
    "#         #padding=2 makes 28x28 image into 32x32\n",
    "#         self.model1 = LeNet()\n",
    "#         self.model1.load_state_dict(torch.load('./trained_model/lenet_pmnist1.pt'))\n",
    "#         self.model2 = LeNet()\n",
    "#         self.model2.load_state_dict(torch.load('./trained_model/lenet_pmnist2.pt'))\n",
    "#         self.model1.to(device)\n",
    "#         self.model2.to(device)\n",
    "\n",
    "#         self.C1_layer = nn.Sequential(\n",
    "#                 CombinationConv2d(1, 6, kernel_size=5, padding=2),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.P2_layer = nn.Sequential(\n",
    "#                 nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.C3_layer = nn.Sequential(\n",
    "#                 C3_layer_full(),\n",
    "#                 #C3_layer(),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.P4_layer = nn.Sequential(\n",
    "#                 nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.C5_layer = nn.Sequential(\n",
    "#                 nn.Linear(5*5*16, 120),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.F6_layer = nn.Sequential(\n",
    "#                 nn.Linear(120, 84),\n",
    "#                 nn.Tanh()\n",
    "#                 )\n",
    "#         self.F7_layer = nn.Linear(84, 10)\n",
    "#         self.tanh = nn.Tanh()\n",
    "        \n",
    "#     def forward(self, x) :\n",
    "#         output = self.C1_layer(x)\n",
    "#         output = self.P2_layer(output)\n",
    "#         output = self.C3_layer(output)\n",
    "#         output = self.P4_layer(output)\n",
    "#         output = output.view(-1,5*5*16)\n",
    "#         output = self.C5_layer(output)\n",
    "#         output = self.F6_layer(output)\n",
    "#         output = self.F7_layer(output)\n",
    "#         return output\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 61706\n",
      "C1_layer.0.weight\n",
      "C1_layer.0.bias\n",
      "C3_layer.0.conv_layer.weight\n",
      "C3_layer.0.conv_layer.bias\n",
      "C5_layer.0.weight\n",
      "C5_layer.0.bias\n",
      "F6_layer.0.weight\n",
      "F6_layer.0.bias\n",
      "F7_layer.weight\n",
      "F7_layer.bias\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "# print total number of trainable parameters\n",
    "param_ct = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Total number of trainable parameters: {param_ct}\")\n",
    "for n, p in model.named_parameters():\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 4\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "np.random.seed(0)\n",
    "perm_inds = list(range(28*28))\n",
    "np.random.shuffle(perm_inds)\n",
    "#fig = plt.figure(2, figsize=(15, 6))\n",
    "#fig.suptitle('Correctly-classified Figures', fontsize=16)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(10) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        plt.imsave('tmp1.png', images[0].cpu().reshape(28,28), cmap = 'gray')\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "        images = images[:, perm_inds].reshape(images.shape[0], 1, 28, 28)\n",
    "        plt.imsave('tmp2.png',images[0].cpu().reshape(28,28), cmap = 'gray')\n",
    "        print(0/0)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "#torch.save(model.state_dict(), './trained_model/\"\n",
    "\n",
    "'''\n",
    "Step 5\n",
    "'''\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "    total += labels.size(0)\n",
    "            \n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e5c4efc6dc3021316245106e8e55db93417baed787fecf7b69731a17f5ba863"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
